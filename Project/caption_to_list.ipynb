{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96bf1ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gupta\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize, Counter\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75d344",
   "metadata": {},
   "source": [
    "### Objective - Use the raw captions from scrapped data and convert it into a list of words and tf/idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd73c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to lemmatize all words in captions\n",
    "def lemmatization(text):\n",
    "    text = nlp(text)\n",
    "    text_lemma = [word.lemma_ for word in text]\n",
    "    return \" \".join(text_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0f25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean caption obtained from scrapper\n",
    "def wrangle(text):\n",
    "    text = text.replace('‚Äú', '\"').replace('‚Äù','\"').replace('‚Äô', \"'\")\n",
    "    printable = set(string.printable)\n",
    "    text = ''.join(filter(lambda x: x in printable, text))\n",
    "   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f885cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stop words and punctuations from the list of caption words\n",
    "def remove_stopwords(lst):\n",
    "    return [word for word in lst if \n",
    "            ( (word not in stopwords.words()) &\n",
    "            (word not in list(string.punctuation)) &\n",
    "            (word not in list(string.digits)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a538dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the cleaning functions\n",
    "def caption_cleaning(data):\n",
    "    # subsetting captions only\n",
    "    captions = data[['caption']]\n",
    "    captions['caption'] = captions['caption'].astype(str).str.strip()\n",
    "    captions['caption'] = captions['caption'].map(lambda s: wrangle(s))\n",
    "    captions['caption_lemma'] = captions['caption'].map(lemmatization)\n",
    "\n",
    "    # creating caption list\n",
    "    captions['caption_list'] = captions['caption_lemma'].map(\n",
    "        lambda row: word_tokenize(row.lower()))\n",
    "    \n",
    "    # removing stop words and punctuation\n",
    "    captions['caption_list'] = captions['caption_list'].map(lambda row: remove_stopwords(row))\n",
    "    \n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e83e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tf dataframe\n",
    "def tf(col):\n",
    "    # creating tf-idf vector\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(col.values)\n",
    "    columns = vectorizer.get_feature_names()\n",
    "\n",
    "    # creating tf idf df\n",
    "    tf_idf_df = pd.DataFrame(X.toarray(), columns=columns)\n",
    "    \n",
    "    return tf_idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47537216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tf idf dataframe\n",
    "def tf_idf(col):\n",
    "    # creating tf-idf vector\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(col.values)\n",
    "    columns = vectorizer.get_feature_names()\n",
    "\n",
    "    # creating tf idf df\n",
    "    tf_idf_df = pd.DataFrame(X.toarray(), columns=columns)\n",
    "    \n",
    "    return tf_idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4580642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tf-idf vectors\n",
    "def caption_tf_idf(captions, idf=True):\n",
    "    # creating a list of caption words\n",
    "    caption_words_list = []\n",
    "    for l in list(captions['caption_list'].values):\n",
    "        caption_words_list = caption_words_list + l\n",
    "\n",
    "    # removing duplicates \n",
    "    caption_words_list = list(set(caption_words_list))\n",
    "\n",
    "    # removing words with length <= 2\n",
    "    caption_words_list = [w for w in caption_words_list if len(w) > 2]\n",
    "\n",
    "    # converting the text to list\n",
    "    captions['caption_cleaned'] = captions['caption_list'].map(lambda lst: ' '.join(lst))\n",
    "    \n",
    "    # get tf idf vec\n",
    "    if idf:\n",
    "        caption_tf_idf = tf_idf(captions['caption_cleaned'])\n",
    "    else:\n",
    "        caption_tf_idf = tf(captions['caption_cleaned'])\n",
    "    caption_words_list = list(set(caption_words_list).intersection(set(caption_tf_idf.columns)))\n",
    "    caption_tf_idf = caption_tf_idf[caption_words_list]\n",
    "    \n",
    "    return caption_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b636cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the cleaning functions\n",
    "def label_cleaning(data):\n",
    "    # subsetting labels only\n",
    "    labels = data[['labels']]\n",
    "    labels['labels'] = labels['labels'].astype(str).str.strip()\n",
    "    labels['labels'] = labels['labels'].map(lambda s: wrangle(s))\n",
    "    labels['labels_lemma'] = labels['labels'].map(lemmatization)\n",
    "\n",
    "    # creating labels list\n",
    "    labels['labels_list'] = labels['labels_lemma'].map(\n",
    "        lambda row: word_tokenize(row.lower()))\n",
    "    \n",
    "    # removing stop words and punctuation: NOT NEEDED FOR LABELS\n",
    "    # labels['labels_list'] = labels['labels_list'].map(lambda row: remove_stopwords(row))\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995a70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tf-idf vectors\n",
    "def labels_tf_idf(labels, idf=True):\n",
    "    # creating a list of labels words\n",
    "    labels_words_list = []\n",
    "    for l in list(labels['labels_list'].values):\n",
    "        labels_words_list = labels_words_list + l\n",
    "\n",
    "    # removing duplicates \n",
    "    labels_words_list = list(set(labels_words_list))\n",
    "\n",
    "    # removing words with length <= 2\n",
    "    labels_words_list = [w for w in labels_words_list if len(w) > 2]\n",
    "\n",
    "    # converting the text to list\n",
    "    labels['labels_cleaned'] = labels['labels_list'].map(lambda lst: ' '.join(lst))\n",
    "    \n",
    "    # get tf idf vec\n",
    "    if idf:\n",
    "        labels_tf_idf = tf_idf(labels['labels_cleaned'])\n",
    "    else:\n",
    "        labels_tf_idf = tf(labels['labels_cleaned'])\n",
    "    labels_words_list = list(set(labels_words_list).intersection(set(labels_tf_idf.columns)))\n",
    "    labels_tf_idf = labels_tf_idf[labels_words_list]\n",
    "    \n",
    "    return labels_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a1643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tf-idf vectors\n",
    "def img_cap_tf_idf(img_cap, idf=True):\n",
    "    # creating a list of img_cap words\n",
    "    words_list = []\n",
    "    for l in list(img_cap['img_cap_list'].values):\n",
    "        words_list = words_list + l\n",
    "\n",
    "    # removing duplicates \n",
    "    words_list = list(set(words_list))\n",
    "\n",
    "    # removing words with length <= 2\n",
    "    words_list = [w for w in words_list if len(w) > 2]\n",
    "\n",
    "    # converting the text to list\n",
    "    img_cap['cleaned'] = img_cap['img_cap_list'].map(lambda lst: ' '.join(lst))\n",
    "    \n",
    "    # get tf idf vec\n",
    "    if idf:\n",
    "        img_cap_tf_idf = tf_idf(img_cap['cleaned'])\n",
    "    else:\n",
    "        img_cap_tf_idf = tf(img_cap['cleaned'])\n",
    "    words_list = list(set(words_list).intersection(set(img_cap_tf_idf.columns)))\n",
    "    img_cap_tf_idf = img_cap_tf_idf[words_list]\n",
    "    \n",
    "    return img_cap_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cc719",
   "metadata": {},
   "source": [
    "## Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "806c99ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_url</th>\n",
       "      <th>caption</th>\n",
       "      <th>n_likes_1000</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>‚Äú100% of myself is nothing compared to 1% of t...</td>\n",
       "      <td>290k</td>\n",
       "      <td>28175</td>\n",
       "      <td>5 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>Meet @azusa25nigo, the founder of @skate_girls...</td>\n",
       "      <td>88k</td>\n",
       "      <td>66716</td>\n",
       "      <td>6 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://instagram.flwo4-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>It takes courage to take the first step üèÉ. Jus...</td>\n",
       "      <td>243k</td>\n",
       "      <td>46306</td>\n",
       "      <td>6 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>‚ÄúThe climate crisis is affecting my sport and ...</td>\n",
       "      <td>159k</td>\n",
       "      <td>87011</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>‚ÄúPeople like to tell us what we can and can‚Äôt ...</td>\n",
       "      <td>252k</td>\n",
       "      <td>67646</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            img_url  \\\n",
       "0           0  https://instagram.flwo4-2.fna.fbcdn.net/v/t51....   \n",
       "1           1  https://instagram.flwo4-2.fna.fbcdn.net/v/t51....   \n",
       "2           2  https://instagram.flwo4-1.fna.fbcdn.net/v/t51....   \n",
       "3           3  https://instagram.flwo4-2.fna.fbcdn.net/v/t51....   \n",
       "4           4  https://instagram.flwo4-2.fna.fbcdn.net/v/t51....   \n",
       "\n",
       "                                             caption n_likes_1000  n_comments  \\\n",
       "0  ‚Äú100% of myself is nothing compared to 1% of t...         290k       28175   \n",
       "1  Meet @azusa25nigo, the founder of @skate_girls...          88k       66716   \n",
       "2  It takes courage to take the first step üèÉ. Jus...         243k       46306   \n",
       "3  ‚ÄúThe climate crisis is affecting my sport and ...         159k       87011   \n",
       "4  ‚ÄúPeople like to tell us what we can and can‚Äôt ...         252k       67646   \n",
       "\n",
       "          age  \n",
       "0  5 days ago  \n",
       "1  6 days ago  \n",
       "2  6 days ago  \n",
       "3  1 week ago  \n",
       "4  1 week ago  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "data = pd.read_csv('Nike/nike_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd6e0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246e8ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-2a8e923f7601>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  captions['caption'] = captions['caption'].astype(str).str.strip()\n",
      "<ipython-input-5-2a8e923f7601>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  captions['caption'] = captions['caption'].map(lambda s: wrangle(s))\n",
      "<ipython-input-5-2a8e923f7601>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  captions['caption_lemma'] = captions['caption'].map(lemmatization)\n",
      "<ipython-input-5-2a8e923f7601>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  captions['caption_list'] = captions['caption_lemma'].map(\n",
      "<ipython-input-5-2a8e923f7601>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  captions['caption_list'] = captions['caption_list'].map(lambda row: remove_stopwords(row))\n"
     ]
    }
   ],
   "source": [
    "captions = caption_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f62bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>caption_lemma</th>\n",
       "      <th>caption_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"100% of myself is nothing compared to 1% of t...</td>\n",
       "      <td>\" 100 % of myself be nothing compare to 1 % of...</td>\n",
       "      <td>[``, 100, nothing, compare, team, ``, kipchoge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meet @azusa25nigo, the founder of @skate_girls...</td>\n",
       "      <td>Meet @azusa25nigo , the founder of @skate_girl...</td>\n",
       "      <td>[meet, azusa25nigo, founder, skate_girls_snap,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It takes courage to take the first step . Just...</td>\n",
       "      <td>it take courage to take the first step . just ...</td>\n",
       "      <td>[courage, first, step, ask, azusa25nigo, azusa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"The climate crisis is affecting my sport and ...</td>\n",
       "      <td>\" the climate crisis be affect my sport and at...</td>\n",
       "      <td>[``, climate, crisis, affect, sport, athlete, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"People like to tell us what we can and can't ...</td>\n",
       "      <td>\" People like to tell we what we can and ca n'...</td>\n",
       "      <td>[``, people, like, tell, n't, n't, hear, real,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Run Dem Crew founder @daddydark rallys the tro...</td>\n",
       "      <td>run Dem Crew founder @daddydark rally the troo...</td>\n",
       "      <td>[run, crew, founder, daddydark, rally, troop, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>20 minutes of balling earned us 449 NikeFuel. ...</td>\n",
       "      <td>20 minute of balling earn we 449 NikeFuel . # ...</td>\n",
       "      <td>[20, minute, balling, earn, 449, nikefuel, fue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>10 explosive minutes from @ShawnJohnsons Nike+...</td>\n",
       "      <td>10 explosive minute from @ShawnJohnsons Nike+ ...</td>\n",
       "      <td>[10, explosive, minute, shawnjohnsons, nike+, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>We crashed a NTC class with @ShawnJohnson at t...</td>\n",
       "      <td>we crash a NTC class with @ShawnJohnson at the...</td>\n",
       "      <td>[crash, ntc, class, shawnjohnson, nike+, fuels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Greatness shines at the Nike+ House of Innovat...</td>\n",
       "      <td>greatness shine at the Nike+ House of Innovati...</td>\n",
       "      <td>[greatness, shine, nike+, house, innovation, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               caption  \\\n",
       "0    \"100% of myself is nothing compared to 1% of t...   \n",
       "1    Meet @azusa25nigo, the founder of @skate_girls...   \n",
       "2    It takes courage to take the first step . Just...   \n",
       "3    \"The climate crisis is affecting my sport and ...   \n",
       "4    \"People like to tell us what we can and can't ...   \n",
       "..                                                 ...   \n",
       "607  Run Dem Crew founder @daddydark rallys the tro...   \n",
       "608  20 minutes of balling earned us 449 NikeFuel. ...   \n",
       "609  10 explosive minutes from @ShawnJohnsons Nike+...   \n",
       "610  We crashed a NTC class with @ShawnJohnson at t...   \n",
       "611  Greatness shines at the Nike+ House of Innovat...   \n",
       "\n",
       "                                         caption_lemma  \\\n",
       "0    \" 100 % of myself be nothing compare to 1 % of...   \n",
       "1    Meet @azusa25nigo , the founder of @skate_girl...   \n",
       "2    it take courage to take the first step . just ...   \n",
       "3    \" the climate crisis be affect my sport and at...   \n",
       "4    \" People like to tell we what we can and ca n'...   \n",
       "..                                                 ...   \n",
       "607  run Dem Crew founder @daddydark rally the troo...   \n",
       "608  20 minute of balling earn we 449 NikeFuel . # ...   \n",
       "609  10 explosive minute from @ShawnJohnsons Nike+ ...   \n",
       "610  we crash a NTC class with @ShawnJohnson at the...   \n",
       "611  greatness shine at the Nike+ House of Innovati...   \n",
       "\n",
       "                                          caption_list  \n",
       "0    [``, 100, nothing, compare, team, ``, kipchoge...  \n",
       "1    [meet, azusa25nigo, founder, skate_girls_snap,...  \n",
       "2    [courage, first, step, ask, azusa25nigo, azusa...  \n",
       "3    [``, climate, crisis, affect, sport, athlete, ...  \n",
       "4    [``, people, like, tell, n't, n't, hear, real,...  \n",
       "..                                                 ...  \n",
       "607  [run, crew, founder, daddydark, rally, troop, ...  \n",
       "608  [20, minute, balling, earn, 449, nikefuel, fue...  \n",
       "609  [10, explosive, minute, shawnjohnsons, nike+, ...  \n",
       "610  [crash, ntc, class, shawnjohnson, nike+, fuels...  \n",
       "611  [greatness, shine, nike+, house, innovation, s...  \n",
       "\n",
       "[612 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fe4d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-323e0b7cd983>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  captions['caption_cleaned'] = captions['caption_list'].map(lambda lst: ' '.join(lst))\n"
     ]
    }
   ],
   "source": [
    "captions_tf_idf_df = caption_tf_idf(captions)\n",
    "captions_tf_idf_df['caption'] = captions['caption']\n",
    "captions_tf_idf_df['caption_list'] = captions['caption_list']\n",
    "captions_tf_idf_df.to_csv('nike_caption_tf_idf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "def920ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-323e0b7cd983>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  captions['caption_cleaned'] = captions['caption_list'].map(lambda lst: ' '.join(lst))\n"
     ]
    }
   ],
   "source": [
    "captions_tf_df = caption_tf_idf(captions, idf=False)\n",
    "captions_tf_df['caption'] = captions['caption']\n",
    "captions_tf_df['caption_list'] = captions['caption_list']\n",
    "captions_tf_df.to_csv('nike_caption_tf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239353de",
   "metadata": {},
   "source": [
    "## Image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f927340d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>url</th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Furniture Picture frame Beard Standing Drawer ...</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sleeve Hat Music Workwear Cool Entertainment F...</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Footwear Jeans Shoe Wheel Sports equipment Ska...</td>\n",
       "      <td>https://instagram.flwo4-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joint Skin Shoe Arm Leg Shorts Purple Knee Com...</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_LIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skin Lip Shoulder White Eyelash Organ Lingerie...</td>\n",
       "      <td>https://instagram.flwo4-2.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Trousers Shirt Fashion Flash photography Perfo...</td>\n",
       "      <td>https://scontent-hel3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Shoe Shorts Sneakers Flooring Floor Player Per...</td>\n",
       "      <td>https://scontent-hel3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Footwear Shorts Shoe Arm yoga pant Active pant...</td>\n",
       "      <td>https://scontent-hel3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Shorts Dance Entertainment Active pants Perfor...</td>\n",
       "      <td>https://scontent-hel3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Sleeve Gesture World Art Entertainment T-shirt...</td>\n",
       "      <td>https://scontent-hel3-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                labels  \\\n",
       "0    Furniture Picture frame Beard Standing Drawer ...   \n",
       "1    Sleeve Hat Music Workwear Cool Entertainment F...   \n",
       "2    Footwear Jeans Shoe Wheel Sports equipment Ska...   \n",
       "3    Joint Skin Shoe Arm Leg Shorts Purple Knee Com...   \n",
       "4    Skin Lip Shoulder White Eyelash Organ Lingerie...   \n",
       "..                                                 ...   \n",
       "607  Trousers Shirt Fashion Flash photography Perfo...   \n",
       "608  Shoe Shorts Sneakers Flooring Floor Player Per...   \n",
       "609  Footwear Shorts Shoe Arm yoga pant Active pant...   \n",
       "610  Shorts Dance Entertainment Active pants Perfor...   \n",
       "611  Sleeve Gesture World Art Entertainment T-shirt...   \n",
       "\n",
       "                                                   url          anger  \\\n",
       "0    https://instagram.flwo4-2.fna.fbcdn.net/v/t51....  VERY_UNLIKELY   \n",
       "1    https://instagram.flwo4-2.fna.fbcdn.net/v/t51....  VERY_UNLIKELY   \n",
       "2    https://instagram.flwo4-1.fna.fbcdn.net/v/t51....  VERY_UNLIKELY   \n",
       "3    https://instagram.flwo4-2.fna.fbcdn.net/v/t51....  VERY_UNLIKELY   \n",
       "4    https://instagram.flwo4-2.fna.fbcdn.net/v/t51....  VERY_UNLIKELY   \n",
       "..                                                 ...            ...   \n",
       "607  https://scontent-hel3-1.cdninstagram.com/v/t51...  VERY_UNLIKELY   \n",
       "608  https://scontent-hel3-1.cdninstagram.com/v/t51...           None   \n",
       "609  https://scontent-hel3-1.cdninstagram.com/v/t51...  VERY_UNLIKELY   \n",
       "610  https://scontent-hel3-1.cdninstagram.com/v/t51...  VERY_UNLIKELY   \n",
       "611  https://scontent-hel3-1.cdninstagram.com/v/t51...           None   \n",
       "\n",
       "               joy       surprise  \n",
       "0    VERY_UNLIKELY  VERY_UNLIKELY  \n",
       "1         UNLIKELY  VERY_UNLIKELY  \n",
       "2    VERY_UNLIKELY  VERY_UNLIKELY  \n",
       "3      VERY_LIKELY  VERY_UNLIKELY  \n",
       "4    VERY_UNLIKELY  VERY_UNLIKELY  \n",
       "..             ...            ...  \n",
       "607       POSSIBLE  VERY_UNLIKELY  \n",
       "608           None           None  \n",
       "609  VERY_UNLIKELY  VERY_UNLIKELY  \n",
       "610  VERY_UNLIKELY  VERY_UNLIKELY  \n",
       "611           None           None  \n",
       "\n",
       "[612 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_excel('Nike/NikeLabels.xlsx')\n",
    "labels.drop(0, inplace=True, axis=0)\n",
    "labels.reset_index(drop=True, inplace=True)\n",
    "labels.columns = [s.lower() for s in labels.columns]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de26fb04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9be0d9978802>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels['labels'] = labels['labels'].astype(str).str.strip()\n",
      "<ipython-input-9-9be0d9978802>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels['labels'] = labels['labels'].map(lambda s: wrangle(s))\n",
      "<ipython-input-9-9be0d9978802>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels['labels_lemma'] = labels['labels'].map(lemmatization)\n",
      "<ipython-input-9-9be0d9978802>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels['labels_list'] = labels['labels_lemma'].map(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_lemma</th>\n",
       "      <th>labels_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Furniture Picture frame Beard Standing Drawer ...</td>\n",
       "      <td>furniture Picture frame Beard Standing Drawer ...</td>\n",
       "      <td>[furniture, picture, frame, beard, standing, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sleeve Hat Music Workwear Cool Entertainment F...</td>\n",
       "      <td>Sleeve Hat Music Workwear Cool Entertainment F...</td>\n",
       "      <td>[sleeve, hat, music, workwear, cool, entertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Footwear Jeans Shoe Wheel Sports equipment Ska...</td>\n",
       "      <td>Footwear Jeans Shoe Wheel Sports equipment Ska...</td>\n",
       "      <td>[footwear, jeans, shoe, wheel, sports, equipme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joint Skin Shoe Arm Leg Shorts Purple Knee Com...</td>\n",
       "      <td>Joint skin Shoe Arm Leg short purple knee Comf...</td>\n",
       "      <td>[joint, skin, shoe, arm, leg, short, purple, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skin Lip Shoulder White Eyelash Organ Lingerie...</td>\n",
       "      <td>skin Lip Shoulder White Eyelash Organ Lingerie...</td>\n",
       "      <td>[skin, lip, shoulder, white, eyelash, organ, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              labels  \\\n",
       "0  Furniture Picture frame Beard Standing Drawer ...   \n",
       "1  Sleeve Hat Music Workwear Cool Entertainment F...   \n",
       "2  Footwear Jeans Shoe Wheel Sports equipment Ska...   \n",
       "3  Joint Skin Shoe Arm Leg Shorts Purple Knee Com...   \n",
       "4  Skin Lip Shoulder White Eyelash Organ Lingerie...   \n",
       "\n",
       "                                        labels_lemma  \\\n",
       "0  furniture Picture frame Beard Standing Drawer ...   \n",
       "1  Sleeve Hat Music Workwear Cool Entertainment F...   \n",
       "2  Footwear Jeans Shoe Wheel Sports equipment Ska...   \n",
       "3  Joint skin Shoe Arm Leg short purple knee Comf...   \n",
       "4  skin Lip Shoulder White Eyelash Organ Lingerie...   \n",
       "\n",
       "                                         labels_list  \n",
       "0  [furniture, picture, frame, beard, standing, d...  \n",
       "1  [sleeve, hat, music, workwear, cool, entertain...  \n",
       "2  [footwear, jeans, shoe, wheel, sports, equipme...  \n",
       "3  [joint, skin, shoe, arm, leg, short, purple, k...  \n",
       "4  [skin, lip, shoulder, white, eyelash, organ, l...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels = label_cleaning(labels)\n",
    "image_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "541b6c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-02a3981c052f>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels['labels_cleaned'] = labels['labels_list'].map(lambda lst: ' '.join(lst))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fog  engineering  lawn  needle  fixture  active      blue  sea  appliance  \\\n",
      "0  0.0          0.0   0.0     0.0      0.0     0.0  0.000000  0.0        0.0   \n",
      "1  0.0          0.0   0.0     0.0      0.0     0.0  0.241971  0.0        0.0   \n",
      "2  0.0          0.0   0.0     0.0      0.0     0.0  0.000000  0.0        0.0   \n",
      "3  0.0          0.0   0.0     0.0      0.0     0.0  0.000000  0.0        0.0   \n",
      "4  0.0          0.0   0.0     0.0      0.0     0.0  0.000000  0.0        0.0   \n",
      "\n",
      "     drawer  ...  net  branch  skateboarder  circle   fashion  boat  cricket  \\\n",
      "0  0.567673  ...  0.0     0.0      0.000000     0.0  0.000000   0.0      0.0   \n",
      "1  0.000000  ...  0.0     0.0      0.000000     0.0  0.000000   0.0      0.0   \n",
      "2  0.000000  ...  0.0     0.0      0.309346     0.0  0.000000   0.0      0.0   \n",
      "3  0.000000  ...  0.0     0.0      0.000000     0.0  0.000000   0.0      0.0   \n",
      "4  0.000000  ...  0.0     0.0      0.000000     0.0  0.192188   0.0      0.0   \n",
      "\n",
      "   skyscraper                                             labels  \\\n",
      "0         0.0  Furniture Picture frame Beard Standing Drawer ...   \n",
      "1         0.0  Sleeve Hat Music Workwear Cool Entertainment F...   \n",
      "2         0.0  Footwear Jeans Shoe Wheel Sports equipment Ska...   \n",
      "3         0.0  Joint Skin Shoe Arm Leg Shorts Purple Knee Com...   \n",
      "4         0.0  Skin Lip Shoulder White Eyelash Organ Lingerie...   \n",
      "\n",
      "                                         labels_list  \n",
      "0  [furniture, picture, frame, beard, standing, d...  \n",
      "1  [sleeve, hat, music, workwear, cool, entertain...  \n",
      "2  [footwear, jeans, shoe, wheel, sports, equipme...  \n",
      "3  [joint, skin, shoe, arm, leg, short, purple, k...  \n",
      "4  [skin, lip, shoulder, white, eyelash, organ, l...  \n",
      "\n",
      "[5 rows x 673 columns]\n"
     ]
    }
   ],
   "source": [
    "image_tf_idf_df = labels_tf_idf(image_labels)\n",
    "image_tf_idf_df['labels'] = image_labels['labels']\n",
    "image_tf_idf_df['labels_list'] = image_labels['labels_list']\n",
    "print(image_tf_idf_df.head())\n",
    "image_tf_idf_df.to_csv('nike_label_tf_idf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "349af6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fog  engineering  lawn  needle  fixture  active  blue  sea  appliance  \\\n",
      "0    0            0     0       0        0       0     0    0          0   \n",
      "1    0            0     0       0        0       0     1    0          0   \n",
      "2    0            0     0       0        0       0     0    0          0   \n",
      "3    0            0     0       0        0       0     0    0          0   \n",
      "4    0            0     0       0        0       0     0    0          0   \n",
      "\n",
      "   drawer  ...  net  branch  skateboarder  circle  fashion  boat  cricket  \\\n",
      "0       2  ...    0       0             0       0        0     0        0   \n",
      "1       0  ...    0       0             0       0        0     0        0   \n",
      "2       0  ...    0       0             1       0        0     0        0   \n",
      "3       0  ...    0       0             0       0        0     0        0   \n",
      "4       0  ...    0       0             0       0        1     0        0   \n",
      "\n",
      "   skyscraper                                             labels  \\\n",
      "0           0  Furniture Picture frame Beard Standing Drawer ...   \n",
      "1           0  Sleeve Hat Music Workwear Cool Entertainment F...   \n",
      "2           0  Footwear Jeans Shoe Wheel Sports equipment Ska...   \n",
      "3           0  Joint Skin Shoe Arm Leg Shorts Purple Knee Com...   \n",
      "4           0  Skin Lip Shoulder White Eyelash Organ Lingerie...   \n",
      "\n",
      "                                         labels_list  \n",
      "0  [furniture, picture, frame, beard, standing, d...  \n",
      "1  [sleeve, hat, music, workwear, cool, entertain...  \n",
      "2  [footwear, jeans, shoe, wheel, sports, equipme...  \n",
      "3  [joint, skin, shoe, arm, leg, short, purple, k...  \n",
      "4  [skin, lip, shoulder, white, eyelash, organ, l...  \n",
      "\n",
      "[5 rows x 673 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-02a3981c052f>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels['labels_cleaned'] = labels['labels_list'].map(lambda lst: ' '.join(lst))\n"
     ]
    }
   ],
   "source": [
    "image_tf_df = labels_tf_idf(image_labels, idf=False)\n",
    "image_tf_df['labels'] = image_labels['labels']\n",
    "image_tf_df['labels_list'] = image_labels['labels_list']\n",
    "print(image_tf_df.head())\n",
    "image_tf_df.to_csv('nike_label_tf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e8873",
   "metadata": {},
   "source": [
    "## Image + Caption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "584baf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_list</th>\n",
       "      <th>caption</th>\n",
       "      <th>caption_list</th>\n",
       "      <th>img_cap_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Furniture Picture frame Beard Standing Drawer ...</td>\n",
       "      <td>[furniture, picture, frame, beard, standing, d...</td>\n",
       "      <td>\"100% of myself is nothing compared to 1% of t...</td>\n",
       "      <td>[``, 100, nothing, compare, team, ``, kipchoge...</td>\n",
       "      <td>[furniture, picture, frame, beard, standing, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sleeve Hat Music Workwear Cool Entertainment F...</td>\n",
       "      <td>[sleeve, hat, music, workwear, cool, entertain...</td>\n",
       "      <td>Meet @azusa25nigo, the founder of @skate_girls...</td>\n",
       "      <td>[meet, azusa25nigo, founder, skate_girls_snap,...</td>\n",
       "      <td>[sleeve, hat, music, workwear, cool, entertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Footwear Jeans Shoe Wheel Sports equipment Ska...</td>\n",
       "      <td>[footwear, jeans, shoe, wheel, sports, equipme...</td>\n",
       "      <td>It takes courage to take the first step . Just...</td>\n",
       "      <td>[courage, first, step, ask, azusa25nigo, azusa...</td>\n",
       "      <td>[footwear, jeans, shoe, wheel, sports, equipme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joint Skin Shoe Arm Leg Shorts Purple Knee Com...</td>\n",
       "      <td>[joint, skin, shoe, arm, leg, short, purple, k...</td>\n",
       "      <td>\"The climate crisis is affecting my sport and ...</td>\n",
       "      <td>[``, climate, crisis, affect, sport, athlete, ...</td>\n",
       "      <td>[joint, skin, shoe, arm, leg, short, purple, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skin Lip Shoulder White Eyelash Organ Lingerie...</td>\n",
       "      <td>[skin, lip, shoulder, white, eyelash, organ, l...</td>\n",
       "      <td>\"People like to tell us what we can and can't ...</td>\n",
       "      <td>[``, people, like, tell, n't, n't, hear, real,...</td>\n",
       "      <td>[skin, lip, shoulder, white, eyelash, organ, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              labels  \\\n",
       "0  Furniture Picture frame Beard Standing Drawer ...   \n",
       "1  Sleeve Hat Music Workwear Cool Entertainment F...   \n",
       "2  Footwear Jeans Shoe Wheel Sports equipment Ska...   \n",
       "3  Joint Skin Shoe Arm Leg Shorts Purple Knee Com...   \n",
       "4  Skin Lip Shoulder White Eyelash Organ Lingerie...   \n",
       "\n",
       "                                         labels_list  \\\n",
       "0  [furniture, picture, frame, beard, standing, d...   \n",
       "1  [sleeve, hat, music, workwear, cool, entertain...   \n",
       "2  [footwear, jeans, shoe, wheel, sports, equipme...   \n",
       "3  [joint, skin, shoe, arm, leg, short, purple, k...   \n",
       "4  [skin, lip, shoulder, white, eyelash, organ, l...   \n",
       "\n",
       "                                             caption  \\\n",
       "0  \"100% of myself is nothing compared to 1% of t...   \n",
       "1  Meet @azusa25nigo, the founder of @skate_girls...   \n",
       "2  It takes courage to take the first step . Just...   \n",
       "3  \"The climate crisis is affecting my sport and ...   \n",
       "4  \"People like to tell us what we can and can't ...   \n",
       "\n",
       "                                        caption_list  \\\n",
       "0  [``, 100, nothing, compare, team, ``, kipchoge...   \n",
       "1  [meet, azusa25nigo, founder, skate_girls_snap,...   \n",
       "2  [courage, first, step, ask, azusa25nigo, azusa...   \n",
       "3  [``, climate, crisis, affect, sport, athlete, ...   \n",
       "4  [``, people, like, tell, n't, n't, hear, real,...   \n",
       "\n",
       "                                        img_cap_list  \n",
       "0  [furniture, picture, frame, beard, standing, d...  \n",
       "1  [sleeve, hat, music, workwear, cool, entertain...  \n",
       "2  [footwear, jeans, shoe, wheel, sports, equipme...  \n",
       "3  [joint, skin, shoe, arm, leg, short, purple, k...  \n",
       "4  [skin, lip, shoulder, white, eyelash, organ, l...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_caption = pd.concat([image_labels[['labels', 'labels_list']], captions[['caption', 'caption_list']]], axis=1)\n",
    "image_caption['img_cap_list'] = image_caption.apply(lambda row: row['labels_list'] + row['caption_list'], axis=1)\n",
    "image_caption.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a70da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check first entry\n",
    "assert len(image_caption.iloc[0, 1]) + len(image_caption.iloc[0, 3]) == len(image_caption.iloc[0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fd3306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   really  shawnjohnsons  needle  toddantonyphoto  nosajthe  broken  fixture  \\\n",
      "0     0.0            0.0     0.0              0.0       0.0     0.0      0.0   \n",
      "1     0.0            0.0     0.0              0.0       0.0     0.0      0.0   \n",
      "2     0.0            0.0     0.0              0.0       0.0     0.0      0.0   \n",
      "3     0.0            0.0     0.0              0.0       0.0     0.0      0.0   \n",
      "4     0.0            0.0     0.0              0.0       0.0     0.0      0.0   \n",
      "\n",
      "   tired  collect  brasileira  ...  universal  narrow  bowerman  corner  rise  \\\n",
      "0    0.0      0.0         0.0  ...        0.0     0.0       0.0     0.0   0.0   \n",
      "1    0.0      0.0         0.0  ...        0.0     0.0       0.0     0.0   0.0   \n",
      "2    0.0      0.0         0.0  ...        0.0     0.0       0.0     0.0   0.0   \n",
      "3    0.0      0.0         0.0  ...        0.0     0.0       0.0     0.0   0.0   \n",
      "4    0.0      0.0         0.0  ...        0.0     0.0       0.0     0.0   0.0   \n",
      "\n",
      "   tomckean  fencer  gomofarah  racer  \\\n",
      "0       0.0     0.0        0.0    0.0   \n",
      "1       0.0     0.0        0.0    0.0   \n",
      "2       0.0     0.0        0.0    0.0   \n",
      "3       0.0     0.0        0.0    0.0   \n",
      "4       0.0     0.0        0.0    0.0   \n",
      "\n",
      "                                        img_cap_list  \n",
      "0  [furniture, picture, frame, beard, standing, d...  \n",
      "1  [sleeve, hat, music, workwear, cool, entertain...  \n",
      "2  [footwear, jeans, shoe, wheel, sports, equipme...  \n",
      "3  [joint, skin, shoe, arm, leg, short, purple, k...  \n",
      "4  [skin, lip, shoulder, white, eyelash, organ, l...  \n",
      "\n",
      "[5 rows x 3269 columns]\n"
     ]
    }
   ],
   "source": [
    "img_cap_tf_idf_df = img_cap_tf_idf(image_caption)\n",
    "img_cap_tf_idf_df['img_cap_list'] = image_caption['img_cap_list']\n",
    "print(img_cap_tf_idf_df.head())\n",
    "img_cap_tf_idf_df.to_csv('nike_img_cap_tf_idf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77dae406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   really  shawnjohnsons  needle  toddantonyphoto  nosajthe  broken  fixture  \\\n",
      "0       0              0       0                0         0       0        0   \n",
      "1       0              0       0                0         0       0        0   \n",
      "2       0              0       0                0         0       0        0   \n",
      "3       0              0       0                0         0       0        0   \n",
      "4       0              0       0                0         0       0        0   \n",
      "\n",
      "   tired  collect  brasileira  ...  universal  narrow  bowerman  corner  rise  \\\n",
      "0      0        0           0  ...          0       0         0       0     0   \n",
      "1      0        0           0  ...          0       0         0       0     0   \n",
      "2      0        0           0  ...          0       0         0       0     0   \n",
      "3      0        0           0  ...          0       0         0       0     0   \n",
      "4      0        0           0  ...          0       0         0       0     0   \n",
      "\n",
      "   tomckean  fencer  gomofarah  racer  \\\n",
      "0         0       0          0      0   \n",
      "1         0       0          0      0   \n",
      "2         0       0          0      0   \n",
      "3         0       0          0      0   \n",
      "4         0       0          0      0   \n",
      "\n",
      "                                        img_cap_list  \n",
      "0  [furniture, picture, frame, beard, standing, d...  \n",
      "1  [sleeve, hat, music, workwear, cool, entertain...  \n",
      "2  [footwear, jeans, shoe, wheel, sports, equipme...  \n",
      "3  [joint, skin, shoe, arm, leg, short, purple, k...  \n",
      "4  [skin, lip, shoulder, white, eyelash, organ, l...  \n",
      "\n",
      "[5 rows x 3269 columns]\n"
     ]
    }
   ],
   "source": [
    "img_cap_tf_df = img_cap_tf_idf(image_caption, idf=False)\n",
    "img_cap_tf_df['img_cap_list'] = image_caption['img_cap_list']\n",
    "print(img_cap_tf_df.head())\n",
    "img_cap_tf_df.to_csv('nike_img_cap_tf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f5afc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert img_cap_tf_df.sum(axis=1).sum() - captions_tf_df.sum(axis=1).sum() - image_tf_df.sum(axis=1).sum() <= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d1cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19fb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa9be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
