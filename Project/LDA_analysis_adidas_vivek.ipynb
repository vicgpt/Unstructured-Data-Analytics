{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8ab1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8218503",
   "metadata": {},
   "source": [
    "# Adidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1926ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLDA(column_name, im_cap_tf, n_topics = 5, alpha_val = 0.5, top_n = None):\n",
    "    \n",
    "    if top_n != None:\n",
    "        l = []\n",
    "        for i in im_cap_tf[column_name]:\n",
    "            l+=i\n",
    "    \n",
    "        wc = Counter(l)\n",
    "        wc.most_common()\n",
    "        \n",
    "        mc_adidas = wc.most_common()[top_n:]\n",
    "        mc_adidas_list = [i[0] for i in mc_adidas]\n",
    "        \n",
    "        texts = im_cap_tf[column_name].apply(lambda x : list(set(x).intersection(set(mc_adidas_list))))\n",
    "    \n",
    "    else:\n",
    "        texts = im_cap_tf[column_name]\n",
    "        \n",
    "    # Create a corpus from a list of texts\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Train the model on the corpus.\n",
    "    lda = LdaModel(corpus, num_topics=n_topics, alpha=alpha_val, id2word = dictionary)\n",
    "    \n",
    "    for p in lda.print_topics(num_topics=n_topics, num_words=10):\n",
    "        print(p[1])\n",
    "    \n",
    "    return lda\n",
    "\n",
    "def createLDA_TFIDF(column_name, im_cap_tf, n_topics = 5, alpha_val = 0.5, top_n = None):\n",
    "    \n",
    "    if top_n != None:\n",
    "        l = []\n",
    "        for i in im_cap_tf[column_name]:\n",
    "            l+=i\n",
    "    \n",
    "        wc = Counter(l)\n",
    "        wc.most_common()\n",
    "        \n",
    "        mc_adidas = wc.most_common()[top_n:]\n",
    "        mc_adidas_list = [i[0] for i in mc_adidas]\n",
    "        \n",
    "        texts = im_cap_tf[column_name].apply(lambda x : list(set(x).intersection(set(mc_adidas_list))))\n",
    "    \n",
    "    else:\n",
    "        texts = im_cap_tf[column_name]\n",
    "        \n",
    "    # Create a corpus from a list of texts\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    model = TfidfModel(corpus)  # fit model\n",
    "\n",
    "    tfidf_corpus = model[corpus]  # apply model to the first corpus document\n",
    "\n",
    "    # Train the model on the corpus.\n",
    "    lda = LdaModel(corpus, num_topics=n_topics, alpha=alpha_val, id2word = dictionary)\n",
    "    \n",
    "    for p in lda.print_topics(num_topics=n_topics, num_words=10):\n",
    "        print(p[1])\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7688c",
   "metadata": {},
   "source": [
    "## Only Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a74be853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fearless', 'strongerforit', 'coding', 'jaque1212', 'leomessi',\n",
      "       'coreyrichproduction', 'baller', 'feel', 'unscripte', 'lelylob',\n",
      "       ...\n",
      "       'writer', 'historical', 'distance', 'without', 'ritaora', 'eiger',\n",
      "       'argentinas', 'collide', 'caption', 'caption_list'],\n",
      "      dtype='object', length=2469)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Adidas/adidas_caption_tf.csv\", index_col=0)\n",
    "print(data.columns)\n",
    "column_name = 'caption_list'\n",
    "data[column_name] = data[column_name].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "24c606f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------LDA without TFIDF ----------------------- \n",
      "\n",
      "0.005*\"store\" + 0.004*\"champion\" + 0.004*\"drop\" + 0.004*\"creator\" + 0.003*\"online\" + 0.003*\"pack\" + 0.003*\"collection\" + 0.003*\"kickoftheweek\" + 0.003*\"worldwide\" + 0.003*\"build\"\n",
      "0.004*\"head\" + 0.004*\"x\" + 0.004*\"collection\" + 0.003*\"start\" + 0.003*\"hometeam\" + 0.003*\"city\" + 0.003*\"look\" + 0.003*\"together\" + 0.003*\"wave\" + 0.003*\"futurecraft\"\n",
      "0.007*\"story\" + 0.004*\"ever\" + 0.004*\"inspire\" + 0.003*\"tap\" + 0.003*\"creator\" + 0.003*\"store\" + 0.003*\"next\" + 0.003*\"together\" + 0.003*\"go\" + 0.003*\"shoe\"\n",
      "0.005*\"speedtakes\" + 0.005*\"creativity\" + 0.004*\"never\" + 0.004*\"well\" + 0.003*\"'s\" + 0.003*\"ever\" + 0.003*\"impossibleisnothe\" + 0.003*\"play\" + 0.003*\"head\" + 0.003*\"share\"\n",
      "0.006*\"'s\" + 0.005*\"go\" + 0.004*\"tap\" + 0.004*\"drop\" + 0.004*\"win\" + 0.003*\"play\" + 0.003*\"1st\" + 0.003*\"ever\" + 0.003*\"fast\" + 0.003*\"street\"\n",
      "\n",
      "------------------------LDA with TFIDF ----------------------- \n",
      "\n",
      "0.005*\"creator\" + 0.005*\"store\" + 0.004*\"'s\" + 0.004*\"shoe\" + 0.004*\"inspire\" + 0.003*\"football\" + 0.003*\"ever\" + 0.003*\"online\" + 0.003*\"speedtakes\" + 0.003*\"next\"\n",
      "0.004*\"store\" + 0.004*\"tap\" + 0.004*\"speedtakes\" + 0.004*\"online\" + 0.003*\"performance\" + 0.003*\"join\" + 0.003*\"top\" + 0.003*\"futurecraft\" + 0.003*\"high\" + 0.003*\"street\"\n",
      "0.005*\"ever\" + 0.005*\"life\" + 0.004*\"creativity\" + 0.004*\"go\" + 0.004*\"creator\" + 0.004*\"adidasfootball\" + 0.003*\"never\" + 0.003*\"quot\" + 0.003*\"head\" + 0.003*\"start\"\n",
      "0.005*\"drop\" + 0.005*\"story\" + 0.004*\"'s\" + 0.004*\"store\" + 0.004*\"give\" + 0.003*\"performance\" + 0.003*\"ultraboost\" + 0.003*\"x\" + 0.003*\"worldwide\" + 0.003*\"next\"\n",
      "0.004*\"play\" + 0.004*\"history\" + 0.004*\"never\" + 0.004*\"story\" + 0.004*\"look\" + 0.003*\"people\" + 0.003*\"collection\" + 0.003*\"go\" + 0.003*\"challenge\" + 0.003*\"mean\"\n"
     ]
    }
   ],
   "source": [
    "print('\\n------------------------LDA without TFIDF ----------------------- \\n')\n",
    "lda_cap = createLDA(column_name=column_name, im_cap_tf=data, n_topics=5, alpha_val=0.5, top_n = 30)\n",
    "\n",
    "print('\\n------------------------LDA with TFIDF ----------------------- \\n')\n",
    "lda_cap_tfidf = createLDA_TFIDF(column_name=column_name, im_cap_tf=data, n_topics=5, alpha_val=0.5, top_n = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2618a7",
   "metadata": {},
   "source": [
    "## Only Image Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e5dddfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['farmworker', 'photograph', 'symbol', 'portrait', 'eyewear', 'toy',\n",
      "       'flag', 'kickflip', 'concrete', 'bicycles',\n",
      "       ...\n",
      "       'leg', 'tire', 'music', 'sportswear', 'serveware', 'bookcase',\n",
      "       'astronomical', 'freeze', 'labels', 'labels_list'],\n",
      "      dtype='object', length=670)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Adidas/adidas_label_tf.csv\", index_col=0)\n",
    "print(data.columns)\n",
    "column_name = 'labels_list'\n",
    "data[column_name] = data[column_name].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3ddd041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------LDA without TFIDF ----------------------- \n",
      "\n",
      "0.019*\"plant\" + 0.017*\"event\" + 0.014*\"entertainment\" + 0.012*\"design\" + 0.011*\"electric\" + 0.011*\"nature\" + 0.011*\"short\" + 0.010*\"shorts\" + 0.010*\"sneaker\" + 0.010*\"automotive\"\n",
      "0.016*\"t\" + 0.015*\"and\" + 0.015*\"muscle\" + 0.014*\"arm\" + 0.014*\"eyebrow\" + 0.012*\"outerwear\" + 0.011*\"shorts\" + 0.011*\"joint\" + 0.010*\"forehead\" + 0.010*\"chin\"\n",
      "0.018*\"black\" + 0.018*\"in\" + 0.018*\"white\" + 0.017*\"nature\" + 0.015*\"sneakers\" + 0.014*\"water\" + 0.012*\"grey\" + 0.012*\"shorts\" + 0.012*\"leisure\" + 0.012*\"and\"\n",
      "\n",
      "------------------------LDA with TFIDF ----------------------- \n",
      "\n",
      "0.028*\"leg\" + 0.023*\"footwear\" + 0.021*\"human\" + 0.019*\"happy\" + 0.018*\"thigh\" + 0.017*\"blue\" + 0.017*\"knee\" + 0.015*\"outdoor\" + 0.015*\"people\" + 0.014*\"gesture\"\n",
      "0.026*\"street\" + 0.021*\"gesture\" + 0.019*\"uniform\" + 0.018*\"thigh\" + 0.013*\"-\" + 0.013*\"player\" + 0.013*\"sport\" + 0.012*\"shirt\" + 0.011*\"muscle\" + 0.011*\"human\"\n",
      "0.021*\"art\" + 0.017*\"-\" + 0.017*\"sport\" + 0.014*\"shirt\" + 0.014*\"player\" + 0.012*\"event\" + 0.011*\"uniform\" + 0.011*\"footwear\" + 0.011*\"plant\" + 0.011*\"t\"\n"
     ]
    }
   ],
   "source": [
    "print('\\n------------------------LDA without TFIDF ----------------------- \\n')\n",
    "lda_cap = createLDA(column_name=column_name, im_cap_tf=data, n_topics=3, alpha_val=0.5, top_n = 30)\n",
    "\n",
    "print('\\n------------------------LDA with TFIDF ----------------------- \\n')\n",
    "lda_cap_tfidf = createLDA_TFIDF(column_name=column_name, im_cap_tf=data, n_topics=3, alpha_val=0.5, top_n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed957b2",
   "metadata": {},
   "source": [
    "## Image Labels + Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "eb981473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fearless', 'strongerforit', 'coding', 'jaque1212', 'concrete',\n",
      "       'leomessi', 'coreyrichproduction', 'feel', 'baller', 'unscripte',\n",
      "       ...\n",
      "       'writer', 'historical', 'distance', 'without', 'ritaora', 'bookcase',\n",
      "       'eiger', 'argentinas', 'collide', 'img_cap_list'],\n",
      "      dtype='object', length=2925)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Adidas/adidas_img_cap_tf.csv\", index_col=0)\n",
    "print(data.columns)\n",
    "column_name = 'img_cap_list'\n",
    "data[column_name] = data[column_name].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0465eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------LDA without TFIDF ----------------------- \n",
      "\n",
      "0.006*\"outdoor\" + 0.006*\"shorts\" + 0.006*\"new\" + 0.005*\"design\" + 0.005*\"plant\" + 0.005*\"world\" + 0.005*\"adidasoriginal\" + 0.004*\"shirt\" + 0.004*\"smile\" + 0.004*\"nature\"\n",
      "0.005*\"body\" + 0.005*\"neck\" + 0.004*\"leisure\" + 0.004*\"cool\" + 0.004*\"t\" + 0.004*\"arm\" + 0.004*\"week\" + 0.004*\"short\" + 0.004*\"chin\" + 0.003*\"black\"\n",
      "0.005*\"event\" + 0.005*\"white\" + 0.005*\"body\" + 0.005*\"shirt\" + 0.005*\"electric\" + 0.005*\"black\" + 0.004*\"neck\" + 0.004*\"--\" + 0.004*\"world\" + 0.004*\"eyebrow\"\n",
      "\n",
      "------------------------LDA with TFIDF ----------------------- \n",
      "\n",
      "0.007*\"sky\" + 0.006*\"heretocreate\" + 0.006*\"happy\" + 0.006*\"create\" + 0.005*\"blue\" + 0.005*\"see\" + 0.005*\"-\" + 0.005*\"new\" + 0.005*\"footwear\" + 0.004*\"street\"\n",
      "0.011*\"leg\" + 0.007*\"sky\" + 0.007*\"thigh\" + 0.007*\"footwear\" + 0.006*\"street\" + 0.006*\"player\" + 0.006*\"human\" + 0.006*\"gesture\" + 0.005*\"outdoor\" + 0.005*\"uniform\"\n",
      "0.007*\"create\" + 0.007*\"street\" + 0.007*\"gesture\" + 0.007*\"heretocreate\" + 0.007*\"art\" + 0.007*\"footwear\" + 0.006*\"thigh\" + 0.006*\"human\" + 0.006*\"-\" + 0.006*\"sky\"\n"
     ]
    }
   ],
   "source": [
    "print('\\n------------------------LDA without TFIDF ----------------------- \\n')\n",
    "lda_cap = createLDA(column_name=column_name, im_cap_tf=data, n_topics=3, alpha_val=0.5, top_n = 30)\n",
    "\n",
    "print('\\n------------------------LDA with TFIDF ----------------------- \\n')\n",
    "lda_cap_tfidf = createLDA_TFIDF(column_name=column_name, im_cap_tf=data, n_topics=3, alpha_val=0.5, top_n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1d497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
