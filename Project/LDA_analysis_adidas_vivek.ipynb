{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ab1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8218503",
   "metadata": {},
   "source": [
    "# Adidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8b2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLDA(column_name, im_cap_tf, n_topics = 5, alpha_val = 0.5, eta_val=0.5, top_n = None):\n",
    "    \n",
    "    if top_n != None:\n",
    "        l = []\n",
    "        for i in im_cap_tf[column_name]:\n",
    "            l+=i\n",
    "    \n",
    "        wc = Counter(l)\n",
    "        wc.most_common()\n",
    "        \n",
    "        mc_adidas = wc.most_common()[top_n:]\n",
    "        mc_adidas_list = [i[0] for i in mc_adidas]\n",
    "        \n",
    "        texts = im_cap_tf[column_name].apply(lambda x : list(set(x).intersection(set(mc_adidas_list))))\n",
    "    \n",
    "    else:\n",
    "        texts = im_cap_tf[column_name]\n",
    "        \n",
    "    # Create a corpus from a list of texts\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Train the model on the corpus.\n",
    "    lda = LdaModel(corpus, num_topics=n_topics, alpha=alpha_val, eta = eta_val, id2word = dictionary)\n",
    "    \n",
    "    for p in lda.print_topics(num_topics=n_topics, num_words=10):\n",
    "        print(p[1])\n",
    "    \n",
    "    return lda\n",
    "\n",
    "def createLDA_TFIDF(column_name, im_cap_tf, n_topics = 5, alpha_val = 0.5, eta_val=0.5, top_n = None):\n",
    "    \n",
    "    if top_n != None:\n",
    "        l = []\n",
    "        for i in im_cap_tf[column_name]:\n",
    "            l+=i\n",
    "    \n",
    "        wc = Counter(l)\n",
    "        wc.most_common()\n",
    "        \n",
    "        mc_adidas = wc.most_common()[top_n:]\n",
    "        mc_adidas_list = [i[0] for i in mc_adidas]\n",
    "        \n",
    "        texts = im_cap_tf[column_name].apply(lambda x : list(set(x).intersection(set(mc_adidas_list))))\n",
    "    \n",
    "    else:\n",
    "        texts = im_cap_tf[column_name]\n",
    "        \n",
    "    # Create a corpus from a list of texts\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    model = TfidfModel(corpus)  # fit model\n",
    "\n",
    "    tfidf_corpus = model[corpus]  # apply model to the first corpus document\n",
    "\n",
    "    # Train the model on the corpus.\n",
    "    lda = LdaModel(corpus, num_topics=n_topics, alpha=alpha_val,eta = eta_val, id2word = dictionary)\n",
    "    \n",
    "    for p in lda.print_topics(num_topics=n_topics, num_words=10):\n",
    "        print(p[1])\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d08c86",
   "metadata": {},
   "source": [
    "## Only Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128b912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fearless', 'strongerforit', 'coding', 'jaque1212', 'leomessi',\n",
      "       'coreyrichproduction', 'baller', 'feel', 'unscripte', 'lelylob',\n",
      "       ...\n",
      "       'writer', 'historical', 'distance', 'without', 'ritaora', 'eiger',\n",
      "       'argentinas', 'collide', 'caption', 'caption_list'],\n",
      "      dtype='object', length=2469)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Adidas/adidas_caption_tf.csv\", index_col=0)\n",
    "print(data.columns)\n",
    "column_name = 'caption_list'\n",
    "data[column_name] = data[column_name].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa6f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------LDA without TFIDF ----------------------- \n",
      "\n",
      "0.002*\"city\" + 0.002*\"play\" + 0.002*\"creator\" + 0.002*\"go\" + 0.002*\"story\" + 0.002*\"head\" + 0.002*\"street\" + 0.002*\"watch\" + 0.002*\"futurecraft\" + 0.002*\"worldwide\"\n",
      "0.003*\"never\" + 0.002*\"head\" + 0.002*\"go\" + 0.002*\"creator\" + 0.002*\"athlete\" + 0.002*\"ever\" + 0.002*\"speedtakes\" + 0.002*\"mean\" + 0.002*\"story\" + 0.002*\"collection\"\n",
      "0.003*\"store\" + 0.002*\"together\" + 0.002*\"tap\" + 0.002*\"win\" + 0.002*\"hometeam\" + 0.002*\"'s\" + 0.002*\"drop\" + 0.002*\"life\" + 0.002*\"help\" + 0.002*\"pack\"\n",
      "0.002*\"story\" + 0.002*\"store\" + 0.002*\"together\" + 0.002*\"'s\" + 0.002*\"champion\" + 0.002*\"celebrate\" + 0.002*\"training\" + 0.002*\"ever\" + 0.002*\"start\" + 0.002*\"drop\"\n",
      "0.002*\"ever\" + 0.002*\"never\" + 0.002*\"creator\" + 0.002*\"creativity\" + 0.002*\"join\" + 0.002*\"performance\" + 0.002*\"go\" + 0.002*\"'s\" + 0.002*\"store\" + 0.002*\"speedtakes\"\n",
      "\n",
      "------------------------LDA with TFIDF ----------------------- \n",
      "\n",
      "0.003*\"'s\" + 0.002*\"pack\" + 0.002*\"history\" + 0.002*\"join\" + 0.002*\"adidasparley\" + 0.002*\"next\" + 0.002*\"shoe\" + 0.002*\"futurecraft\" + 0.002*\"never\" + 0.002*\"go\"\n",
      "0.002*\"watch\" + 0.002*\"story\" + 0.002*\"ever\" + 0.002*\"creator\" + 0.002*\"together\" + 0.002*\"street\" + 0.002*\"creativity\" + 0.002*\"never\" + 0.002*\"head\" + 0.002*\"worldcup\"\n",
      "0.002*\"store\" + 0.002*\"ever\" + 0.002*\"go\" + 0.002*\"creator\" + 0.002*\"together\" + 0.002*\"drop\" + 0.002*\"hometeam\" + 0.002*\"futurecraft\" + 0.002*\"speedtakes\" + 0.002*\"step\"\n",
      "0.002*\"'s\" + 0.002*\"start\" + 0.002*\"find\" + 0.002*\"creator\" + 0.002*\"ever\" + 0.002*\"celebrate\" + 0.002*\"store\" + 0.002*\"collection\" + 0.002*\"never\" + 0.002*\"performance\"\n",
      "0.003*\"store\" + 0.002*\"online\" + 0.002*\"tap\" + 0.002*\"never\" + 0.002*\"story\" + 0.002*\"head\" + 0.002*\"drop\" + 0.002*\"go\" + 0.002*\"worldwide\" + 0.002*\"history\"\n"
     ]
    }
   ],
   "source": [
    "n_topics=5\n",
    "alpha_val=0.7\n",
    "eta_val = 0.7\n",
    "top_n =30\n",
    "\n",
    "print('\\n------------------------LDA without TFIDF ----------------------- \\n')\n",
    "lda_cap = createLDA(column_name=column_name, im_cap_tf=data, n_topics=n_topics, alpha_val=alpha_val, eta_val = eta_val, top_n=top_n)\n",
    "\n",
    "print('\\n------------------------LDA with TFIDF ----------------------- \\n')\n",
    "lda_cap_tfidf = createLDA_TFIDF(column_name=column_name, im_cap_tf=data, n_topics=n_topics, alpha_val=alpha_val, eta_val=eta_val, top_n=top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b92764",
   "metadata": {},
   "source": [
    "## Only Image Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed48a605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['farmworker', 'photograph', 'symbol', 'portrait', 'eyewear', 'toy',\n",
      "       'flag', 'kickflip', 'concrete', 'bicycles',\n",
      "       ...\n",
      "       'leg', 'tire', 'music', 'sportswear', 'serveware', 'bookcase',\n",
      "       'astronomical', 'freeze', 'labels', 'labels_list'],\n",
      "      dtype='object', length=670)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Adidas/adidas_label_tf.csv\", index_col=0)\n",
    "print(data.columns)\n",
    "column_name = 'labels_list'\n",
    "data[column_name] = data[column_name].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f0b3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------LDA without TFIDF ----------------------- \n",
      "\n",
      "0.018*\"leg\" + 0.018*\"thigh\" + 0.017*\"human\" + 0.017*\"gesture\" + 0.013*\"happy\" + 0.013*\"street\" + 0.013*\"player\" + 0.012*\"blue\" + 0.012*\"footwear\" + 0.011*\"art\"\n",
      "0.018*\"street\" + 0.018*\"footwear\" + 0.016*\"sport\" + 0.014*\"uniform\" + 0.012*\"outdoor\" + 0.012*\"human\" + 0.011*\"leg\" + 0.011*\"event\" + 0.011*\"player\" + 0.011*\"gesture\"\n",
      "0.017*\"-\" + 0.015*\"leg\" + 0.015*\"thigh\" + 0.013*\"art\" + 0.012*\"happy\" + 0.012*\"gesture\" + 0.012*\"t\" + 0.011*\"footwear\" + 0.010*\"shirt\" + 0.010*\"blue\"\n",
      "\n",
      "------------------------LDA with TFIDF ----------------------- \n",
      "\n",
      "0.017*\"-\" + 0.015*\"happy\" + 0.014*\"art\" + 0.013*\"sport\" + 0.013*\"blue\" + 0.013*\"thigh\" + 0.012*\"street\" + 0.011*\"leg\" + 0.011*\"uniform\" + 0.011*\"gesture\"\n",
      "0.018*\"thigh\" + 0.018*\"leg\" + 0.018*\"footwear\" + 0.014*\"gesture\" + 0.014*\"knee\" + 0.013*\"human\" + 0.012*\"body\" + 0.011*\"street\" + 0.011*\"player\" + 0.010*\"happy\"\n",
      "0.018*\"human\" + 0.015*\"gesture\" + 0.015*\"leg\" + 0.015*\"street\" + 0.012*\"footwear\" + 0.011*\"thigh\" + 0.011*\"uniform\" + 0.011*\"art\" + 0.011*\"black\" + 0.010*\"blue\"\n"
     ]
    }
   ],
   "source": [
    "n_topics=3\n",
    "alpha_val=0.7\n",
    "eta_val = 0.7\n",
    "top_n =10\n",
    "\n",
    "print('\\n------------------------LDA without TFIDF ----------------------- \\n')\n",
    "lda_cap = createLDA(column_name=column_name, im_cap_tf=data, n_topics=n_topics, alpha_val=alpha_val, eta_val = eta_val, top_n=top_n)\n",
    "\n",
    "print('\\n------------------------LDA with TFIDF ----------------------- \\n')\n",
    "lda_cap_tfidf = createLDA_TFIDF(column_name=column_name, im_cap_tf=data, n_topics=n_topics, alpha_val=alpha_val, eta_val=eta_val, top_n=top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2eea6e",
   "metadata": {},
   "source": [
    "## Image Labels + Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea17d365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fearless', 'strongerforit', 'coding', 'jaque1212', 'concrete',\n",
      "       'leomessi', 'coreyrichproduction', 'feel', 'baller', 'unscripte',\n",
      "       ...\n",
      "       'writer', 'historical', 'distance', 'without', 'ritaora', 'bookcase',\n",
      "       'eiger', 'argentinas', 'collide', 'img_cap_list'],\n",
      "      dtype='object', length=2925)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Adidas/adidas_img_cap_tf.csv\", index_col=0)\n",
    "print(data.columns)\n",
    "column_name = 'img_cap_list'\n",
    "data[column_name] = data[column_name].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d331111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------LDA without TFIDF ----------------------- \n",
      "\n",
      "0.005*\"shirt\" + 0.004*\"t\" + 0.004*\"new\" + 0.004*\"body\" + 0.003*\"shorts\" + 0.003*\"entertainment\" + 0.003*\"nature\" + 0.003*\"event\" + 0.003*\"white\" + 0.003*\"adidasoriginal\"\n",
      "0.004*\"neck\" + 0.004*\"world\" + 0.003*\"event\" + 0.003*\"arm\" + 0.003*\"body\" + 0.003*\"leisure\" + 0.003*\"nature\" + 0.003*\"shirt\" + 0.003*\"forehead\" + 0.003*\"eyebrow\"\n",
      "0.004*\"design\" + 0.004*\"world\" + 0.004*\"electric\" + 0.004*\"black\" + 0.003*\"outdoor\" + 0.003*\"white\" + 0.003*\"--\" + 0.003*\"shoulder\" + 0.003*\"head\" + 0.003*\"body\"\n",
      "0.004*\"black\" + 0.004*\"outdoor\" + 0.003*\"shorts\" + 0.003*\"and\" + 0.003*\"new\" + 0.003*\"--\" + 0.003*\"leisure\" + 0.003*\"arm\" + 0.003*\"shirt\" + 0.003*\"sneakers\"\n",
      "0.004*\"in\" + 0.004*\"body\" + 0.003*\"short\" + 0.003*\"nature\" + 0.003*\"and\" + 0.003*\"plant\" + 0.003*\"outdoor\" + 0.003*\"smile\" + 0.003*\"shorts\" + 0.003*\"design\"\n",
      "\n",
      "------------------------LDA with TFIDF ----------------------- \n",
      "\n",
      "0.003*\"new\" + 0.003*\"body\" + 0.003*\"plant\" + 0.003*\"world\" + 0.003*\"short\" + 0.003*\"design\" + 0.003*\"ball\" + 0.003*\"shirt\" + 0.003*\"event\" + 0.003*\"eyebrow\"\n",
      "0.003*\"leisure\" + 0.003*\"outdoor\" + 0.003*\"nature\" + 0.003*\"white\" + 0.003*\"in\" + 0.003*\"neck\" + 0.003*\"world\" + 0.003*\"smile\" + 0.003*\"eyebrow\" + 0.003*\"shirt\"\n",
      "0.003*\"body\" + 0.003*\"black\" + 0.003*\"outdoor\" + 0.003*\"electric\" + 0.003*\"neck\" + 0.003*\"t\" + 0.003*\"white\" + 0.003*\"adidasoriginal\" + 0.003*\"shirt\" + 0.003*\"design\"\n",
      "0.004*\"neck\" + 0.003*\"event\" + 0.003*\"body\" + 0.003*\"arm\" + 0.003*\"world\" + 0.003*\"design\" + 0.003*\"head\" + 0.003*\"shoulder\" + 0.003*\"nature\" + 0.003*\"black\"\n",
      "0.004*\"--\" + 0.004*\"shorts\" + 0.004*\"outdoor\" + 0.004*\"shirt\" + 0.004*\"t\" + 0.003*\"entertainment\" + 0.003*\"available\" + 0.003*\"and\" + 0.003*\"in\" + 0.003*\"event\"\n"
     ]
    }
   ],
   "source": [
    "n_topics=5\n",
    "alpha_val=0.7\n",
    "eta_val = 0.7\n",
    "top_n =30\n",
    "\n",
    "print('\\n------------------------LDA without TFIDF ----------------------- \\n')\n",
    "lda_cap = createLDA(column_name=column_name, im_cap_tf=data, n_topics=n_topics, alpha_val=alpha_val, eta_val = eta_val, top_n=top_n)\n",
    "\n",
    "print('\\n------------------------LDA with TFIDF ----------------------- \\n')\n",
    "lda_cap_tfidf = createLDA_TFIDF(column_name=column_name, im_cap_tf=data, n_topics=n_topics, alpha_val=alpha_val, eta_val=eta_val, top_n=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf9887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
